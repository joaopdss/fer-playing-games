{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhdkilTGyciLPJjs5uMRWi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joaopdss/fer-playing-games/blob/main/FER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE1UXXmtP-Ol",
        "outputId": "d9306b6d-bcc4-434b-f770-184454bb4f2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "J9QRITJUOJjd"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/Datasets/fer_dataset.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jMkYldwzWh5a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = tf.keras.utils.image_dataset_from_directory(directory=\"/content/dataset\",\n",
        "                                            color_mode=\"rgb\",\n",
        "                                            label_mode=\"categorical\",\n",
        "                                            batch_size=32,\n",
        "                                            image_size=(48, 48),\n",
        "                                            shuffle=True,\n",
        "                                            seed=42,\n",
        "                                            validation_split=0.2,\n",
        "                                            subset=\"both\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "924ioVSfe7_v",
        "outputId": "d15429fc-ca44-4bf4-866c-710736ffabef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40476 files belonging to 5 classes.\n",
            "Using 32381 files for training.\n",
            "Using 8095 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process(image, label):\n",
        "  image = tf.cast(image/255., tf.float32)\n",
        "  return image,label\n",
        "\n",
        "train_data = train_data.map(process)\n",
        "val_data = val_data.map(process)"
      ],
      "metadata": {
        "id": "Vn6HoeAIt2iG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veihyK4vigxQ",
        "outputId": "da3453a8-59a1-482e-9729-267abeea5631"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_MapDataset element_spec=(TensorSpec(shape=(None, 48, 48, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 5), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_data.take(1):\n",
        "  for i in range(2):\n",
        "    ax = plt.subplot(6, 6, i+1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "N64SGhJ1ilqb",
        "outputId": "2da88e5a-6b84-4c0f-b833-6ff826efeeb7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJ0AAABICAYAAADs1fdKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAA6klEQVR4nO3YsQ0DMQwAsSjI/ivrV/gm58Jk7UIQDio8u7sfCH1PD8B9REdOdORER0505ERHTnTkREfu9/bhzPxzjiNO/4vfulOXjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIiY6c6MiJjpzoyImOnOjIze7u6SG4i0tHTnTkREdOdORER0505ERHTnTkREfuAXwzDolvht42AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch size 64\n",
        "tf.random.set_seed(42)\n",
        "# Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(48, 48, 3)),\n",
        "  tf.keras.layers.Conv2D(512, (3,3), activation=\"relu\", padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Conv2D(256, (3,3), activation=\"relu\", padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.MaxPool2D(2),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  tf.keras.layers.MaxPool2D(2),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\"),\n",
        "  tf.keras.layers.MaxPool2D(2),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(5, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"checkpoint/\",\n",
        "                                                         save_weights_only=False,\n",
        "                                                         save_best_only=True,\n",
        "                                                         save_freq=\"epoch\",\n",
        "                                                         verbose=1)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\n",
        "                              patience=8, min_lr=0.00001)\n",
        "\n",
        "# Fit the model\n",
        "model_1.fit(train_data, epochs=8, callbacks=[reduce_lr, checkpoint_callback], validation_data=val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MUKP2C_jJlZ",
        "outputId": "2df49053-58b7-43de-889a-b91462abfa2f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "1012/1012 [==============================] - ETA: 0s - loss: 1.7265 - accuracy: 0.2540\n",
            "Epoch 1: val_loss improved from inf to 1.53208, saving model to checkpoint/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1012/1012 [==============================] - 122s 110ms/step - loss: 1.7265 - accuracy: 0.2540 - val_loss: 1.5321 - val_accuracy: 0.3401 - lr: 0.0010\n",
            "Epoch 2/8\n",
            "1012/1012 [==============================] - ETA: 0s - loss: 1.4710 - accuracy: 0.3602\n",
            "Epoch 2: val_loss did not improve from 1.53208\n",
            "1012/1012 [==============================] - 101s 100ms/step - loss: 1.4710 - accuracy: 0.3602 - val_loss: 1.6340 - val_accuracy: 0.2007 - lr: 0.0010\n",
            "Epoch 3/8\n",
            "1012/1012 [==============================] - ETA: 0s - loss: 1.3190 - accuracy: 0.4498\n",
            "Epoch 3: val_loss improved from 1.53208 to 1.29927, saving model to checkpoint/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1012/1012 [==============================] - 107s 106ms/step - loss: 1.3190 - accuracy: 0.4498 - val_loss: 1.2993 - val_accuracy: 0.4618 - lr: 0.0010\n",
            "Epoch 4/8\n",
            "1012/1012 [==============================] - ETA: 0s - loss: 1.1936 - accuracy: 0.5118\n",
            "Epoch 4: val_loss improved from 1.29927 to 1.06355, saving model to checkpoint/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1012/1012 [==============================] - 107s 106ms/step - loss: 1.1936 - accuracy: 0.5118 - val_loss: 1.0635 - val_accuracy: 0.5847 - lr: 0.0010\n",
            "Epoch 5/8\n",
            "1012/1012 [==============================] - ETA: 0s - loss: 1.1015 - accuracy: 0.5524\n",
            "Epoch 5: val_loss did not improve from 1.06355\n",
            "1012/1012 [==============================] - 100s 98ms/step - loss: 1.1015 - accuracy: 0.5524 - val_loss: 1.1675 - val_accuracy: 0.5508 - lr: 0.0010\n",
            "Epoch 6/8\n",
            "1012/1012 [==============================] - ETA: 0s - loss: 1.0494 - accuracy: 0.5757\n",
            "Epoch 6: val_loss improved from 1.06355 to 0.98346, saving model to checkpoint/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1012/1012 [==============================] - 102s 101ms/step - loss: 1.0494 - accuracy: 0.5757 - val_loss: 0.9835 - val_accuracy: 0.6189 - lr: 0.0010\n",
            "Epoch 7/8\n",
            "1012/1012 [==============================] - ETA: 0s - loss: 1.0086 - accuracy: 0.5983\n",
            "Epoch 7: val_loss did not improve from 0.98346\n",
            "1012/1012 [==============================] - 100s 98ms/step - loss: 1.0086 - accuracy: 0.5983 - val_loss: 1.0018 - val_accuracy: 0.6163 - lr: 0.0010\n",
            "Epoch 8/8\n",
            "1012/1012 [==============================] - ETA: 0s - loss: 0.9673 - accuracy: 0.6150\n",
            "Epoch 8: val_loss improved from 0.98346 to 0.92080, saving model to checkpoint/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1012/1012 [==============================] - 102s 101ms/step - loss: 0.9673 - accuracy: 0.6150 - val_loss: 0.9208 - val_accuracy: 0.6441 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ddee82c0ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jkNnYs7bqCXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}